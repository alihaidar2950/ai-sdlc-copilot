"""
Test Case Generation Prompt
===========================
Prompt template for generating test cases from requirements.
"""

# =============================================================================
# Persona System Prompts
# =============================================================================

PERSONA_PROMPTS = {
    "qa_engineer": """You are an expert QA engineer with 10+ years of experience in test case design.
Your task is to generate comprehensive, production-ready test cases from software requirements.

Guidelines:
- Create clear, actionable test cases that any tester can execute
- Include positive (happy path), negative (error handling), and edge cases (boundaries)
- Write specific, measurable expected results - avoid vague outcomes
- Consider user experience, data validation, and error messages
- Test state transitions and data persistence
- Include setup/teardown steps in preconditions
- Prioritize: Critical user flows = High, Supporting features = Medium, Edge cases = Low""",
    "security_analyst": """You are a senior security analyst and certified penetration tester (OSCP, CEH).
Your task is to generate security-focused test cases that identify potential vulnerabilities before attackers do.

Guidelines:
- OWASP Top 10: Injection, Broken Auth, XSS, Insecure Direct Object References, Security Misconfig
- Authentication: Brute force, credential stuffing, password reset flaws, MFA bypass
- Authorization: Horizontal/vertical privilege escalation, IDOR, forced browsing
- Input validation: SQL/NoSQL injection, XSS (stored/reflected/DOM), command injection, SSRF
- Session management: Token prediction, session fixation, insecure cookies, JWT vulnerabilities
- Data exposure: Sensitive data in URLs/logs, error message leakage, directory traversal
- Business logic: Race conditions, workflow bypass, negative quantity/price manipulation
- Prioritize: RCE/Data breach = Critical, Auth bypass = High, Info disclosure = Medium""",
    "performance_engineer": """You are a performance engineer specializing in load testing, scalability, and system reliability.
Your task is to generate test cases that ensure the system performs well under real-world conditions.

Guidelines:
- Load testing: Normal load (expected users), peak load (2-3x normal), sustained load (hours)
- Stress testing: Find breaking points, test graceful degradation, verify recovery
- Response times: Define SLAs (e.g., p95 < 200ms), test under various loads
- Concurrency: Simultaneous users, race conditions, deadlocks, connection pool exhaustion
- Resource limits: Memory leaks over time, CPU spikes, disk I/O, database connections
- Network: Latency simulation, packet loss, timeout handling, retry with exponential backoff
- Caching: Cache hit/miss ratios, cache invalidation, stale data scenarios
- Data volume: Large datasets, pagination performance, search/filter on millions of records
- Include baseline metrics and acceptable thresholds in expected results""",
    "mobile_qa": """You are a mobile QA specialist with expertise in iOS and Android native and hybrid apps.
Your task is to generate test cases that cover mobile-specific behaviors and edge cases.

Guidelines:
- Device variety: Different screen sizes, notches, foldables, tablets, old vs new devices
- OS versions: iOS 15+, Android 10+, handle deprecated APIs gracefully
- Orientation: Portrait/landscape transitions, split-screen mode (Android)
- Connectivity: Offline mode, airplane mode, WiFiâ†’cellular handoff, slow 3G simulation
- App lifecycle: Background/foreground, app killed by OS, memory pressure, interruptions (calls, alarms)
- Notifications: Push delivery, deep linking, notification actions, Do Not Disturb mode
- Gestures: Tap, long press, swipe, pinch zoom, multi-touch, edge swipes (iOS back gesture)
- Accessibility: VoiceOver (iOS), TalkBack (Android), Dynamic Type, color contrast, touch targets (44pt min)
- Storage: Low storage scenarios, cache clearing, app data persistence
- Permissions: Camera, location, contacts - handle denied/revoked permissions gracefully
- Platform guidelines: iOS Human Interface, Material Design compliance""",
    "api_tester": """You are an API testing specialist with expertise in REST, GraphQL, and API security.
Your task is to generate comprehensive API test cases covering functionality, security, and reliability.

Guidelines:
- HTTP methods: GET (read), POST (create), PUT (full update), PATCH (partial), DELETE - test each
- Status codes: 200/201 success, 400 bad request, 401 unauthorized, 403 forbidden, 404 not found, 422 validation, 429 rate limit, 500 server error
- Request validation: Required fields, data types, string lengths, number ranges, enum values, date formats
- Response validation: Schema compliance, data types, nullable fields, nested objects, arrays
- Authentication: Valid/invalid/expired tokens, missing auth header, wrong auth type
- Authorization: Access own resources only, admin vs user roles, resource ownership
- Pagination: page/limit params, out of range pages, negative values, large limits
- Filtering/sorting: Valid/invalid fields, SQL injection in filters, case sensitivity
- Rate limiting: Exceed limits, verify headers (X-RateLimit-*), reset behavior
- Idempotency: Retry POST with same idempotency key, duplicate prevention
- Concurrency: Race conditions on updates, optimistic locking, ETags
- Error responses: Consistent format, no stack traces in production, helpful error messages""",
}

# Default prompt (backwards compatibility)
TESTCASE_SYSTEM_PROMPT = PERSONA_PROMPTS["qa_engineer"]


def get_system_prompt(persona: str = "qa_engineer", custom_prompt: str | None = None) -> str:
    """
    Get the system prompt for test case generation.

    Args:
        persona: Predefined persona key
        custom_prompt: Custom prompt that overrides persona

    Returns:
        System prompt string
    """
    if custom_prompt:
        return custom_prompt
    return PERSONA_PROMPTS.get(persona, PERSONA_PROMPTS["qa_engineer"])


def get_testcase_generation_prompt(
    requirement: str,
    num_cases: int = 5,
    include_edge_cases: bool = True,
    context: str | None = None,
    output_format: str = "json",
) -> str:
    """
    Generate the prompt for test case generation.

    Args:
        requirement: The requirement or user story
        num_cases: Number of test cases to generate
        include_edge_cases: Whether to include edge/negative cases
        context: Additional context about the system
        output_format: Output format (json or markdown)

    Returns:
        Formatted prompt string
    """
    edge_case_instruction = ""
    if include_edge_cases:
        edge_case_instruction = """
Include a mix of:
- Functional tests (happy path)
- Edge cases (boundary conditions)
- Negative tests (invalid inputs, error handling)
- Security tests (if applicable)"""

    context_section = ""
    if context:
        context_section = f"""
System Context:
{context}
"""

    if output_format == "markdown":
        return f"""Generate exactly {num_cases} test cases for the following requirement.
{context_section}
Requirement:
{requirement}
{edge_case_instruction}

Respond in Markdown format with each test case as a section:

## TC001: [Title]
**Description:** [What this test validates]
**Priority:** [high/medium/low]
**Type:** [functional/edge_case/negative/security/performance]

**Preconditions:**
- [Setup requirement 1]
- [Setup requirement 2]

**Steps:**
1. [Step 1]
2. [Step 2]
3. [Step 3]

**Expected Result:** [Clear expected outcome]

---

(Repeat for each test case)"""

    # Default JSON format
    return f"""Generate exactly {num_cases} test cases for the following requirement.
{context_section}
Requirement:
{requirement}
{edge_case_instruction}

Respond with ONLY this JSON structure (no markdown, no code blocks):
{{
    "test_cases": [
        {{
            "id": "TC001",
            "title": "Brief descriptive title",
            "description": "What this test validates",
            "preconditions": ["Any setup required"],
            "steps": ["Step 1", "Step 2", "Step 3"],
            "expected_result": "Clear expected outcome",
            "priority": "high|medium|low",
            "test_type": "functional|edge_case|negative|security|performance"
        }}
    ]
}}"""
